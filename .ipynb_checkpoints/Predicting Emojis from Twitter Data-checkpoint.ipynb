{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Predicting Emojis from Twitter Data"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### Nicholas Farn, Ekaterina Koplenko, Maithili Bhide"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Emoji have become more and more prominent in todayâ€™s social media. Since their initial appearance in Japan in the 1990s, it has been found that emoji are used by over ninety-two percent of the online population in 2015 [1]. Due to the indicated trend, numerous NLP applications can benefit from the emoji interpretation capability.\n",
    "\n",
    "In this project, we aim to implement and to train the following models: a bidirectional LSTM, a CNN, and a bag of words. Our objective is to predict one of 5, 10, and 20 most frequently used emoticons for a given sentence."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## 1. Data Set"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "We acquired a pre-processed dataset containing 584,600 tweets, posted between October 2015 and May 2016 in the US [2]. The dataset consists of three sets containing tweets from the top 5, 10, and 20 most common emojis. Each set is split into training, validation, and test sets with the training sets containing 2-5 hundred thousand tweets and the validation and test sets containing a couple ten thousand.\n",
    "\n",
    "Preprocessing consisted of replacing user mentions with the symbol \"@user\", as well as replacing words that occur less than 5 times with the symbol \"< unk >\". Punctuation such as commas and quotation marks are separated from words with a space and are treated as words themselves. A brief sample "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style>\n",
       "    .dataframe thead tr:only-child th {\n",
       "        text-align: right;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: left;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>Tweet</th>\n",
       "      <th>Emoji</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>funny how you change when certain people are a...</td>\n",
       "      <td>eoji1f602</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>@user hahahah yeeahhh right</td>\n",
       "      <td>eoji1f602</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>@user i like the last one</td>\n",
       "      <td>eoji1f602</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>good lawrd your blankets smell amazing</td>\n",
       "      <td>eoji1f60d</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>@user lol my nigga you mad</td>\n",
       "      <td>eoji1f602</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>5</th>\n",
       "      <td>i love having beautiful friends ! happy holida...</td>\n",
       "      <td>eoji2764</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>6</th>\n",
       "      <td>guy at gas station : \" did you know , ford bac...</td>\n",
       "      <td>eoji1f602</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>7</th>\n",
       "      <td>@user : @user bih that's gone be my step chil...</td>\n",
       "      <td>eoji1f602</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>8</th>\n",
       "      <td>welcome to the nba i told yall its another jus...</td>\n",
       "      <td>eoji1f525</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>9</th>\n",
       "      <td>oh my girls were so beautiful tonight ! #lizzi...</td>\n",
       "      <td>eoji1f602</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "                                               Tweet      Emoji\n",
       "0  funny how you change when certain people are a...  eoji1f602\n",
       "1                       @user hahahah yeeahhh right   eoji1f602\n",
       "2                         @user i like the last one   eoji1f602\n",
       "3            good lawrd your blankets smell amazing   eoji1f60d\n",
       "4                        @user lol my nigga you mad   eoji1f602\n",
       "5  i love having beautiful friends ! happy holida...   eoji2764\n",
       "6  guy at gas station : \" did you know , ford bac...  eoji1f602\n",
       "7   @user : @user bih that's gone be my step chil...  eoji1f602\n",
       "8  welcome to the nba i told yall its another jus...  eoji1f525\n",
       "9  oh my girls were so beautiful tonight ! #lizzi...  eoji1f602"
      ]
     },
     "execution_count": 1,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "import pandas as pd\n",
    "pd.read_csv('./data/5_test', delimiter='\\t', names=['Tweet', 'Emoji']).head(10)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## 2. Baseline"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "For the baseline we have implemented a bag of words classifier as it has been known to be successful for classification tasks like sentiment analysis and topic modeling. Our task is to remove the emoji from the sequence of tokens and use it as a label both for training and testing. Each message/tweet is represented as a vector. The most informative tokens (including punctuation marks) are selected using term frequency-inverse document frequency (TF-IDF). L2 regularized logistic regression is used to make the predictions."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "<tr>\n",
    "    <td> <img src=\"images/Fig_5.png\" alt=\"Drawing\" style=\"width: 500px;\"/> </td>\n",
    "    <td> <img src=\"images/Fig_10.png\" alt=\"Drawing\" style=\"width: 500px;\"/> </td>\n",
    "</tr>"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Based on the results for the 5 most frequent, 10 most frequent and 20 most frequent emoji in our dataset we can see that the baseline model has a high preference towards predicting the first<tear_of_joy> and second<red_heart> most frequent emoji. From the above confusion matrix for 5 most frequent emojis we can see that the third<face_with_heart_eyes> most frequent emoji gets misclassified as the first most frequent one more than half the times. Similar misclassification with preference towards predicting the first or second most frequent emoji can be seen in the top 10 and top 20 most frequent emoji confusion matrix as well. "
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "The baseline classifier does considerably well on our dataset. The performance metrics for this model were seen to be consistent with the results published in the paper 'Are Emojis Predictable?'[2].\n",
    "For our future models, we have tried to reduce the prediction bias towards the most frequent class and improve the classification accuracy of emojis occurring less frequently. This has been done by modeling a CNN and LSTM as explaind further. "
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## 3. Convolutional Neural Network"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Another model noted to do well is a convolutional neural network[2][3]. The model consisted of passing 64 filters of width 3, 4, and 5 over a sequence of word embeddings (of dimension 50) which a max pool is applied to produce a fixed size output. The output then fed directly into a fully connected softmax used to predict the emoji class. During training the fully connected layer is subjected to dropout. Embeddings were initialized using pre-trained GloVe embeddings from twitter data. Words without matching GloVe embeddings were initialized from a uniform distribution from -1 to 1."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "<img src='images/cnn_model.png' />"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "In addition to the basic CNN, increased fully connected layers and a highway network was introduced between the convolutional layer output and fully connected layer. Deep highway networks are noted to have improved training time over deep neural networks as well as produce similar outputs between semantically similar words and phrases with vastly different input[3]. A highway layer is defined by eq. 1 where $\\circ$ is an element wise multiplication."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "$$y = \\text{relu}(W_H x + b_H) \\circ \\sigma(W_T x + b_T) + (1 - \\sigma(W_T x + b_T)) \\circ x$$"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Since the output of a highway network is of the same dimension as its inputs, $W_H$ and $W_T$ are therefore square matrices."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Dropout is applied between every layer from the convolutional output up to, but not including, the softmax layer in order to regularize the model. Weights are initialized using the Glorot uniform distribution. Biases are initialized to 0 except for $b_T$ which is initialized from a uniform distribution from -4 to -2. This is so highway networks tend to produce similar output as its inputs at first. All models were trained using the Adam optimizer."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## 4. Long-Short Term Memory"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "We explore both uni- and bi-directional LSTM models to solve the sequential emoji classification problem with GloVe word embeddings. LSTM neural networks are being actively researched as they show promising results and can provide state-of-the-art performance.\n",
    "\n",
    "Two models were constructed and analyzed. First model consists of a unidirectional LSTM hidden layer while an extra bidirectional LSTM layer added prior to the LSTM layer in the second model. Both neural networks accept tweets that have been tokenized, enumerated, and padded or truncated to gain a uniform length of 35. All of the unknown words are given and <unk> token and placed in the zeroth position in the vocabulary. The first hidden layer creates GloVe word embeddings to represent all the words in the training set. The embedding weights are being learned along with the model. The output dimension of the resulted embedded vector is set to 100. In the final stage, the output is passed through the softmax function to determine the most probable emoji.\n",
    "\n",
    "Adam optimization and dropout techniques were integrated to improve performance of both models. During training, we noticed that for some experiments testing accuracy increases while validation accuracy drops. This signified overfitting issues within the neural network. To compensate for overfitting,  two intermediate dropout layers were introduced. Additionally, we used a popular stochastic optimization algorithm in NLP called Adam. This method computes different learning rates for various parameters unlike traditional SGD where learning rate remains unchanged."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## 5. Results"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "We tested our models using a weighted F1 score as an indicator of performance."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "<center><b>F1 Scores by Model per Top N Emojis</b></center>\n",
    "\n",
    "|  | baseline | CNN | Resampled CNN | Highway CNN | LSTM | Bi-LSTM |\n",
    "|--|----------|----------|----------|----------|----------|----------|\n",
    "|5 | 0.592061 | 0.549705 | <b>0.595257</b> | 0.564256 | 0.564256 | 0.593087 |\n",
    "|10| 0.441736 | <b>0.447219</b> | 0.390082 | 0.423835 | 0.423835 | 0.443731 |\n",
    "|20| <b>0.347743</b> | 0.208166 | 0.292820 | 0.284491 | 0.284491 | 0.342432 |"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Unfortunately, as one might notice none of our models performed siginificantly better than our baseline model."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### 5.1 Baseline"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "<tr>\n",
    "    <td> <img src=\"images/Fig_5.png\" alt=\"Drawing\" style=\"width: 300px;\"/> </td>\n",
    "    <td> <img src=\"images/Fig_10.png\" alt=\"Drawing\" style=\"width: 300px;\"/> </td>\n",
    "    <td> <img src=\"images/Fig_20.png\" alt=\"Drawing\" style=\"width: 300px;\"/> </td>\n",
    "</tr>"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### 5.2 CNN"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "<table style=\"width:100%\">\n",
    "    <tr>\n",
    "        <th><center>CNN</center></th>\n",
    "        <th><center>Resampled</center></th>\n",
    "        <th><center>Highway</center></th>\n",
    "    </tr>\n",
    "    <tr>\n",
    "        <td><img src='images/5_confusion.png' /></td>\n",
    "        <td><img src='images/5_resample.png' /></td>\n",
    "        <td><img src='images/5_highway.png' /></td>\n",
    "    </tr>\n",
    "</table>\n",
    "\n",
    "<b>Figure 1.</b> Confusion matrix of top 5 emojis for various CNNs. The most common emoji is denoted as the class 0 while the least common is denoted as the class 4."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Here we can compare the results of the various CNNs. As one would expect, the resampled CNN does a better job at predicting the less common classes, however this is to the detriment of now confusing the first and third most common emojis together. However both of these perform better than a CNN with a single highway layer since it fails to distinguish the third emoji from the first nearly at all."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### 5.3 LSTM"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Testing showed that BILSTM followed by LSTM performs better than LSTM network for both 5 and 10 emoji sets. However, during further testing on 20 emoji both models show almost identical results. During development, we aimed to implement a similar model examined in the research article Are Emojis Predictable[2]? Our BILSTM model outperforms the one described in the paper; therefore, we consider our model a success. "
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## 6. Conclusion"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": []
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## References"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "[1]: http://emogi.com/documents/Emoji_Report_2015.pdf \"Emoji Report 2015\", emoji.com, 2015\n",
    "\n",
    "[2]: https://arxiv.org/pdf/1702.07285.pdf F. Barbieri, M. Ballesteros, H. Saggion, \"Are Emojis Predictable?\", 2016\n",
    "\n",
    "[3]: https://web.stanford.edu/class/cs224n/reports/2762064.pdf L. Zhao, C. Zeng, \"Using Neural Networks to Predict Emoji Usage from Twitter Data\"\n",
    "\n",
    "[4]: https://arxiv.org/abs/1408.5882 Y. Kim, \"Convolutional Neural Networks for Sentence Classification\", 2014\n",
    "\n",
    "[5]: https://arxiv.org/abs/1505.00387 R. Srivastava, K. Greff, J. Schmidhuber, \"Highway Networks\", 2015 "
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Code"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "https://github.com/neonrights/emoji_predictor"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 2",
   "language": "python",
   "name": "python2"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 2
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython2",
   "version": "2.7.12"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
